{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desafio 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Vectorización de documentos\n",
    "\n",
    "Vectorizar documentos. Tomar 5 documentos al azar y medir similaridad con el resto de los documentos. Estudiar los 5 documentos más similares de cada uno analizar si tiene sentido la similaridad según el contenido del texto y la etiqueta de clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se inicializa el vectorizador TF-IDF y se entrena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfvect = TfidfVectorizer()\n",
    "\n",
    "X_train = tfidfvect.fit_transform(newsgroups_train.data)\n",
    "y_train = newsgroups_train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "Shape: (11314, 101631)\n",
      "Number of documents: 11314\n",
      "Vocabulary size: 101631\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train))\n",
    "print(f'Shape: {X_train.shape}')\n",
    "print(f'Number of documents: {X_train.shape[0]}')\n",
    "print(f'Vocabulary size: {X_train.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtienen los identificadores de cinco documentos al azar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly selected documents indices: [11256  7608  5426  5959  3603]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(40)\n",
    "\n",
    "documents_idx = np.random.choice(X_train.shape[0], 5)\n",
    "print(f\"Randomly selected documents indices: {documents_idx}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis del documento: **11256**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtiene los índices de los documentos más similares al documento 11256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar documents to document 11256: [ 1794 10714  8506   111  9736]\n"
     ]
    }
   ],
   "source": [
    "main_idx = 11256\n",
    "\n",
    "# Calculate the cosine similarity between the main document and all the other documents\n",
    "cos_sim = cosine_similarity(X_train[main_idx], X_train)[0]\n",
    "\n",
    "# Get the indices of the most similar documents\n",
    "most_similar_idx = np.argsort(cos_sim)[::-1][1:6]\n",
    "\n",
    "print(f'Most similar documents to document {main_idx}: {most_similar_idx}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se muestra el contenido del documento seleccionado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class for document 11256: comp.sys.ibm.pc.hardware\n",
      "Content:\n",
      ": I need to know the Pins to connect to make a loopback connector for a serial\n",
      ": port so I can build one.  The loopback connector is used to test the \n",
      ": serial port.\n",
      ": \n",
      ": Thanks for any help.\n",
      ": \n",
      ": \n",
      ": Steve\n",
      ": \n",
      "Me Too!!!!!!!\n",
      "skcgoh@tartarus.uwa.edu.au\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Class for document {main_idx}: {newsgroups_train.target_names[y_train[main_idx]]}')\n",
    "print(f'Content:\\n{newsgroups_train.data[main_idx]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El documento seleccionado parece estar relacionado con algun servicio de atención al cliente, en el área de tecnología. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_similarity(\n",
    "    most_similar_idx: list,\n",
    "    documents: list,\n",
    "    labels: list,\n",
    "    cosine_sim_matrix: np.ndarray,\n",
    "    main_idx: int,\n",
    "    top_n: int = 5\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Analyze the similarity of selected documents with the rest of the documents.\n",
    "\n",
    "    Parameters:\n",
    "    - most_similar_idx: List of indices of the most similar documents.\n",
    "    - documents: List of documents in the dataset.\n",
    "    - labels: List of labels corresponding to each document.\n",
    "    - cosine_sim_matrix: Cosine similarity matrix of the documents.\n",
    "    - main_idx: Index of the main document to analyze.\n",
    "    - top_n: Number of most similar documents to retrieve for each selected document.\n",
    "    \"\"\"\n",
    "    class_names = newsgroups_train.target_names\n",
    "    \n",
    "    print(f\"\\nTop {top_n} Similar Documents:\\n{'-'*50}\")\n",
    "\n",
    "    for idx in most_similar_idx:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Analyzing Document {idx}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        print(f\"Content:\\n{documents[idx][:200]}\\n\")\n",
    "        print(f\"Document Class: {class_names[labels[idx]]}\")\n",
    "        print(f\"Main Document Class: {class_names[labels[main_idx]]}\")\n",
    "        print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se analizan los documentos más similares "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 Similar Documents:\n",
      "--------------------------------------------------\n",
      "\n",
      "==================================================\n",
      "Analyzing Document 1794\n",
      "==================================================\n",
      "Content:\n",
      "I need to know the Pins to connect to make a loopback connector for a serial\n",
      "port so I can build one.  The loopback connector is used to test the \n",
      "serial port.\n",
      "\n",
      "Thanks for any help.\n",
      "\n",
      "\n",
      "Document Class: comp.sys.ibm.pc.hardware\n",
      "Main Document Class: comp.sys.ibm.pc.hardware\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Analyzing Document 10714\n",
      "==================================================\n",
      "Content:\n",
      "Subject says it  all.  Please email soon.  \n",
      "skcgoh@tartarus.uwa.edu.au\n",
      "\n",
      "\n",
      "Document Class: comp.sys.ibm.pc.hardware\n",
      "Main Document Class: comp.sys.ibm.pc.hardware\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Analyzing Document 8506\n",
      "==================================================\n",
      "Content:\n",
      "\n",
      "\n",
      "From a recent BYTE magazine i got the following:\n",
      "\n",
      "[Question and part of the answer deleted]\n",
      "\n",
      "  If you are handy with a soldering iron, the loopback plugs are easy to\n",
      "make.  On a serial RS-232 nine-p\n",
      "\n",
      "Document Class: comp.sys.ibm.pc.hardware\n",
      "Main Document Class: comp.sys.ibm.pc.hardware\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Analyzing Document 111\n",
      "==================================================\n",
      "Content:\n",
      "\n",
      "It would depend on the requirements of the poster's data, for some\n",
      "purposes 1/256 resolution (with or without calibration curve).\n",
      "\n",
      "\n",
      "Otherwise the other possibilities would be:\n",
      "\n",
      "1) get a digital volta\n",
      "\n",
      "Document Class: comp.sys.mac.hardware\n",
      "Main Document Class: comp.sys.ibm.pc.hardware\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Analyzing Document 9736\n",
      "==================================================\n",
      "Content:\n",
      "I have used both my serial ports with a modem and a serial printer, \n",
      "so I cannot use Appletalk.  Is there a Ethernet to Localtalk hardware\n",
      "that will let me use the Ethernet port on my Q700 as a Localt\n",
      "\n",
      "Document Class: comp.sys.mac.hardware\n",
      "Main Document Class: comp.sys.ibm.pc.hardware\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "analyze_similarity(\n",
    "    most_similar_idx=most_similar_idx, \n",
    "    documents=newsgroups_train.data, \n",
    "    labels=y_train, \n",
    "    cosine_sim_matrix=cos_sim, \n",
    "    main_idx=main_idx\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver en el resultado de la celda anterior. La mayoría de los documentos más similares tienen tópicos con servicios de atención al cliente, relacionados con computación y tecnología. Uno de los documentos tiene un correo electrónico de contacto de una institución educativa, por lo que la similitud puede ir porque en el documento 11256 se menciona un correo electrónico también."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis del documento: **7608**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtiene los índices de los documentos más similares al documento **7608**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar documents to document 7608: [2172 6387 7545 2800 9986]\n"
     ]
    }
   ],
   "source": [
    "main_idx = 7608\n",
    "\n",
    "# Calculate the cosine similarity between the main document and all the other documents\n",
    "cos_sim = cosine_similarity(X_train[main_idx], X_train)[0]\n",
    "\n",
    "# Get the indices of the most similar documents\n",
    "most_similar_idx = np.argsort(cos_sim)[::-1][1:6]\n",
    "\n",
    "print(f'Most similar documents to document {main_idx}: {most_similar_idx}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se muestra el contenido del documento seleccionado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class for document 7608: sci.space\n",
      "Content:\n",
      "Other idea for old space crafts is as navigation beacons and such..\n",
      "Why not?? If you can put them on \"safe\" \"pause\" mode.. why not have them be\n",
      "activated by a signal from a space craft (manned?) to act as a naviagtion\n",
      "beacon, to take a directional plot on??\n"
     ]
    }
   ],
   "source": [
    "print(f'Class for document {main_idx}: {newsgroups_train.target_names[y_train[main_idx]]}')\n",
    "print(f'Content:\\n{newsgroups_train.data[main_idx]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El documento que se va a analizar esta relacionado con las ciencias aerospaciales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se analizan los documentos más similares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 Similar Documents:\n",
      "--------------------------------------------------\n",
      "\n",
      "==================================================\n",
      "Analyzing Document 2172\n",
      "==================================================\n",
      "Content:\n",
      "   Other idea for old space crafts is as navigation beacons and such..\n",
      "   Why not??\n",
      "\n",
      "Because to be any use as a nav point you need to know -exactly- where\n",
      "it is, which means you either nail it to some\n",
      "\n",
      "Document Class: sci.space\n",
      "Main Document Class: sci.space\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Analyzing Document 6387\n",
      "==================================================\n",
      "Content:\n",
      "\n",
      "\n",
      "\n",
      "There is a whole constellation of custom built navigation beacon satellites\n",
      "in the process of being phased out right now. The TRANSIT/OSCAR satellites\n",
      "are being replaced by GPS. Or were you thinkin\n",
      "\n",
      "Document Class: sci.space\n",
      "Main Document Class: sci.space\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Analyzing Document 7545\n",
      "==================================================\n",
      "Content:\n",
      "There is an interesting opinion piece in the business section of today's\n",
      "LA Times (Thursday April 15, 1993, p. D1).  I thought I'd post it to\n",
      "stir up some flame wars - I mean reasoned debate.  Let me \n",
      "\n",
      "Document Class: sci.space\n",
      "Main Document Class: sci.space\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Analyzing Document 2800\n",
      "==================================================\n",
      "Content:\n",
      "Archive-name: space/net\n",
      "Last-modified: $Date: 93/04/01 14:39:15 $\n",
      "\n",
      "NETWORK RESOURCES\n",
      "\n",
      "OVERVIEW\n",
      "\n",
      "    You may be reading this document on any one of an amazing variety of\n",
      "    computers, so much of the m\n",
      "\n",
      "Document Class: sci.space\n",
      "Main Document Class: sci.space\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Analyzing Document 9986\n",
      "==================================================\n",
      "Content:\n",
      "Archive-name: space/groups\n",
      "Last-modified: $Date: 93/04/01 14:39:08 $\n",
      "\n",
      "SPACE ACTIVIST/INTEREST/RESEARCH GROUPS AND SPACE PUBLICATIONS\n",
      "\n",
      "    GROUPS\n",
      "\n",
      "    AIA -- Aerospace Industry Association. Professiona\n",
      "\n",
      "Document Class: sci.space\n",
      "Main Document Class: sci.space\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "analyze_similarity(\n",
    "    most_similar_idx=most_similar_idx, \n",
    "    documents=newsgroups_train.data, \n",
    "    labels=y_train, \n",
    "    cosine_sim_matrix=cos_sim, \n",
    "    main_idx=main_idx\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de este documento la similaridad es más clara, todos los documentos más similares tienen tópicos relacionados con las ciencias aerospaciales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis del documento: **5426**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtiene los índices de los documentos más similares al documento **5426**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar documents to document 5426: [11124  7902  9030   955  6635]\n"
     ]
    }
   ],
   "source": [
    "main_idx = 5426\n",
    "\n",
    "# Calculate the cosine similarity between the main document and all the other documents\n",
    "cos_sim = cosine_similarity(X_train[main_idx], X_train)[0]\n",
    "\n",
    "# Get the indices of the most similar documents\n",
    "most_similar_idx = np.argsort(cos_sim)[::-1][1:6]\n",
    "\n",
    "print(f'Most similar documents to document {main_idx}: {most_similar_idx}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se muestra el contenido del documento seleccionado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class for document 5426: rec.motorcycles\n",
      "Content:\n",
      "\n",
      "\n",
      "Hmmm.. The LDDC security guards over here in Docklands only place parking \n",
      "stickers on the drivers SIDE windows.. But on reflection that could still \n",
      "cause an accident.. Suppose it's because people aren't as litigious over \n",
      "here as in the states :-)\n",
      "\n",
      "Stephen\n"
     ]
    }
   ],
   "source": [
    "print(f'Class for document {main_idx}: {newsgroups_train.target_names[y_train[main_idx]]}')\n",
    "print(f'Content:\\n{newsgroups_train.data[main_idx]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso el documento parece estar relacionado algun tipo de comentario deportivo. Por la información de la etiqueta se puede inferir que el documento es de la categoría de motociclismo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se analizan los documentos más similares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 Similar Documents:\n",
      "--------------------------------------------------\n",
      "\n",
      "==================================================\n",
      "Analyzing Document 11124\n",
      "==================================================\n",
      "Content:\n",
      "PATRICK\n",
      "1st rd:\tPens over Isles in 4.\n",
      "\tDevils over Caps in 6.\n",
      "2nd:\tPens over Devils in 7.\n",
      "\n",
      "ADAMS\n",
      "1st rd: B's over Sabres in 5.\n",
      "\tNords over Habs in 5.\n",
      "2nd:\tB's over Nords in 6.\n",
      "\n",
      "NORRIS\n",
      "1st:\tHawks over \n",
      "\n",
      "Document Class: rec.sport.hockey\n",
      "Main Document Class: rec.motorcycles\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Analyzing Document 7902\n",
      "==================================================\n",
      "Content:\n",
      "\n",
      "(1)  Stephen said you took a quote out of context\n",
      "(2)  You noted that Stephen had not replied to some other t.r.m article\n",
      "     (call it A) that took a quote out of context\n",
      "(3)  But the lack of eviden\n",
      "\n",
      "Document Class: talk.religion.misc\n",
      "Main Document Class: rec.motorcycles\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Analyzing Document 9030\n",
      "==================================================\n",
      "Content:\n",
      "\n",
      "(not that logic has anything to do with it, but...)\n",
      "I can see the liability of putting stickers on the car while it was moving,\n",
      "or something, but it's the BDI that chooses to start and then drive the\n",
      "\n",
      "Document Class: rec.motorcycles\n",
      "Main Document Class: rec.motorcycles\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Analyzing Document 955\n",
      "==================================================\n",
      "Content:\n",
      "\n",
      "The Supreme Court seems to disagree with you -- they have stated that\n",
      "\"the people\" is a term of art refering to an individual right, and\n",
      "have explicitly mentioned the second amendment as an example.\n",
      "\n",
      "\n",
      "Document Class: sci.crypt\n",
      "Main Document Class: rec.motorcycles\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Analyzing Document 6635\n",
      "==================================================\n",
      "Content:\n",
      "THE WHITE HOUSE\n",
      "\n",
      "                    Office of the Press Secretary\n",
      "______________________________________________________________\n",
      "For Immediate Release                             April 15, 1993     \n",
      "\n",
      "\n",
      "Document Class: talk.politics.misc\n",
      "Main Document Class: rec.motorcycles\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "analyze_similarity(\n",
    "    most_similar_idx=most_similar_idx, \n",
    "    documents=newsgroups_train.data, \n",
    "    labels=y_train, \n",
    "    cosine_sim_matrix=cos_sim, \n",
    "    main_idx=main_idx\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este caso, los documentos detectados como más similares tienen tópicos más diversos. Dos de ellos estan relacionados con comentarios deportivos, uno con comentarios sobre hockey y otro con comentarios sobre motociclismo. El resto de documentos estan relacionados a religión, política y criptografía, para estos últimos los motivos de la similaridad no son tan claros, pero posiblemente se deba a que contienen palabras o caracteres similares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis del documento: **5959**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtiene los índices de los documentos más similares al documento **5959**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar documents to document 5959: [ 913  919 3746 5826 4271]\n"
     ]
    }
   ],
   "source": [
    "main_idx = 5959\n",
    "\n",
    "# Calculate the cosine similarity between the main document and all the other documents\n",
    "cos_sim = cosine_similarity(X_train[main_idx], X_train)[0]\n",
    "\n",
    "# Get the indices of the most similar documents\n",
    "most_similar_idx = np.argsort(cos_sim)[::-1][1:6]\n",
    "\n",
    "print(f'Most similar documents to document {main_idx}: {most_similar_idx}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se muestra el contenido del documento seleccionado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class for document 5959: comp.sys.ibm.pc.hardware\n",
      "Content:\n",
      "\n",
      "\n",
      "We have plenty of computer labs where the computers are left on all the\n",
      "time. I don't see any shorter lifespan than the ones we have in the\n",
      "offices which does get turned off at the end of the day. In fact, some\n",
      "of the computers in the labs have outlived some of the same ones in the\n",
      "offices. But it goes both ways so can't conclude anything.\n"
     ]
    }
   ],
   "source": [
    "print(f'Class for document {main_idx}: {newsgroups_train.target_names[y_train[main_idx]]}')\n",
    "print(f'Content:\\n{newsgroups_train.data[main_idx]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El documento parece estar relacionado con tecnología, específicamente computación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se analizan los documentos más similares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 Similar Documents:\n",
      "--------------------------------------------------\n",
      "\n",
      "==================================================\n",
      "Analyzing Document 913\n",
      "==================================================\n",
      "Content:\n",
      "The recent rise of nostalgia in this group, combined with the\n",
      "  incredible level of utter bullshit, has prompted me to comb\n",
      "  through my archives and pull out some of \"The Best of Alt.Atheism\"\n",
      "  for y\n",
      "\n",
      "Document Class: alt.atheism\n",
      "Main Document Class: comp.sys.ibm.pc.hardware\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Analyzing Document 919\n",
      "==================================================\n",
      "Content:\n",
      "Accounts of Anti-Armenian Human Right Violatins in Azerbaijan #009\n",
      "                 Prelude to Current Events in Nagorno-Karabakh\n",
      "\n",
      "      +--------------------------------------------------------------\n",
      "\n",
      "Document Class: talk.politics.mideast\n",
      "Main Document Class: comp.sys.ibm.pc.hardware\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Analyzing Document 3746\n",
      "==================================================\n",
      "Content:\n",
      "THE WHITE HOUSE\n",
      "\n",
      "                  Office of the Press Secretary\n",
      "                 (Vancouver, British Columbia) \n",
      "______________________________________________________________\n",
      "\n",
      "\n",
      "                      \n",
      "\n",
      "Document Class: talk.politics.misc\n",
      "Main Document Class: comp.sys.ibm.pc.hardware\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Analyzing Document 5826\n",
      "==================================================\n",
      "Content:\n",
      "A listmember (D Andrew Killie, I think) wrote, in response to the\n",
      "suggestion that genocide may sometimes be the will of God:\n",
      "\n",
      " > Any God who works that way is indescribably evil,\n",
      " > and unworthy of my\n",
      "\n",
      "Document Class: soc.religion.christian\n",
      "Main Document Class: comp.sys.ibm.pc.hardware\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Analyzing Document 4271\n",
      "==================================================\n",
      "Content:\n",
      "THE WHITE HOUSE\n",
      "\n",
      "                    Office of the Press Secretary\n",
      "______________________________________________________________\n",
      "For Immediate Release                             April 13, 1993     \n",
      "\n",
      "\n",
      "Document Class: talk.politics.misc\n",
      "Main Document Class: comp.sys.ibm.pc.hardware\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "analyze_similarity(\n",
    "    most_similar_idx=most_similar_idx, \n",
    "    documents=newsgroups_train.data, \n",
    "    labels=y_train, \n",
    "    cosine_sim_matrix=cos_sim, \n",
    "    main_idx=main_idx\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los documentos, estan relacionados con tópicos de religión y política. Ninguno de los documentos más similares tiene relación con el tópico del documento seleccionado. Nuevamente, puede ser que la similaridad se deba a palabras, caracteres o una estructura similar en los documentos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis del documento: **3603**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtiene los índices de los documentos más similares al documento **3603**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar documents to document 3603: [5928 2495 1739 8101 9764]\n"
     ]
    }
   ],
   "source": [
    "main_idx = 3603\n",
    "\n",
    "# Calculate the cosine similarity between the main document and all the other documents\n",
    "cos_sim = cosine_similarity(X_train[main_idx], X_train)[0]\n",
    "\n",
    "# Get the indices of the most similar documents\n",
    "most_similar_idx = np.argsort(cos_sim)[::-1][1:6]\n",
    "\n",
    "print(f'Most similar documents to document {main_idx}: {most_similar_idx}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se muestra el contenido del documento seleccionado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class for document 3603: comp.sys.mac.hardware\n",
      "Content:\n",
      "\n",
      "\n",
      "...\n",
      "\n",
      "\n",
      "Mac sound hardware is diverse; some macs play in stereo and\n",
      "mix the output (the SE/30 for instance) while others play in\n",
      "stereo but ONLY has the left channel for the speaker, while\n",
      "some are \"truly\" mono (like the LC)\n",
      "\n",
      "Developers know that stuff played in the left channel is\n",
      "guaranteed to be heard, while the right channel isn't. Some\n",
      "send data to both, some only send data to the left channel\n",
      "(the first is preferrable, of course)\n",
      "\n",
      "Cheers,\n",
      "\n",
      "\t\t\t\t\t/ h+\n"
     ]
    }
   ],
   "source": [
    "print(f'Class for document {main_idx}: {newsgroups_train.target_names[y_train[main_idx]]}')\n",
    "print(f'Content:\\n{newsgroups_train.data[main_idx]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El documento parece estar relacionado con servicios de atención al cliente, en el área de tecnología."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se analizan los documentos más similares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 Similar Documents:\n",
      "--------------------------------------------------\n",
      "\n",
      "==================================================\n",
      "Analyzing Document 5928\n",
      "==================================================\n",
      "Content:\n",
      "or\n",
      "there\n",
      "\n",
      "\n",
      "Okay, I guess its time for a quick explanation of Mac sound.\n",
      "\n",
      "The original documentation for the sound hardware (IM-3) documents how to\n",
      "make sound by directly accessing hardware.  Basically\n",
      "\n",
      "Document Class: comp.sys.mac.hardware\n",
      "Main Document Class: comp.sys.mac.hardware\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Analyzing Document 2495\n",
      "==================================================\n",
      "Content:\n",
      "Hi.  I think I have a problem with the stereo sound output on my Quadra\n",
      "900, but I am not totally sure because my roomate has the same problem\n",
      "on his PowerBook 170.  Any info or experience anyopne has\n",
      "\n",
      "Document Class: comp.sys.mac.hardware\n",
      "Main Document Class: comp.sys.mac.hardware\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Analyzing Document 1739\n",
      "==================================================\n",
      "Content:\n",
      "I'm looking for a used/inexpensive audio mixer.  I need at least \n",
      "4 channels of stereo input and 1 channel of stereo output, but I would\n",
      "prefer 8 or more input channels.  Each channel needs to have at\n",
      "\n",
      "Document Class: misc.forsale\n",
      "Main Document Class: comp.sys.mac.hardware\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Analyzing Document 8101\n",
      "==================================================\n",
      "Content:\n",
      "\n",
      "\n",
      "\n",
      "The Sound Driver is pretty ok, since it's fast. Sound Manager used by the\n",
      "book is *useless*. Disposing of sound channels as soon as sound has completed\n",
      "is out of the question for games with smooth \n",
      "\n",
      "Document Class: comp.sys.mac.hardware\n",
      "Main Document Class: comp.sys.mac.hardware\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Analyzing Document 9764\n",
      "==================================================\n",
      "Content:\n",
      "I missed the first part of this thread; are you switching line level or\n",
      "speaker level audio?\n",
      "If line level, there's a single chip 4x1 *stereo* audio switch available\n",
      "that switches 4 two-channel inputs\n",
      "\n",
      "Document Class: sci.electronics\n",
      "Main Document Class: comp.sys.mac.hardware\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "analyze_similarity(\n",
    "    most_similar_idx=most_similar_idx, \n",
    "    documents=newsgroups_train.data, \n",
    "    labels=y_train, \n",
    "    cosine_sim_matrix=cos_sim, \n",
    "    main_idx=main_idx\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este caso, la mayoría de los documentos más similares tienen tópicos relacionados con servicios de atención al cliente, en el área de tecnología. Los demás documentos estan relacionados con electrónica y lo que parece ser un mensaje relacao con un componente de audio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Entrenamiento de modelos\n",
    "\n",
    "Entrenar modelos de clasificación Naïve Bayes para maximizar el desempeño de clasificación (f1-score macro) en el conjunto de datos de test. Considerar cambiar parámteros de instanciación del vectorizador y los modelos y probar modelos de Naïve Bayes Multinomial y ComplementNB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se definen los conjuntos de entrenamiento y test. Además, las variables objetivo y las características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = newsgroups_train.data\n",
    "y_train = newsgroups_train.target\n",
    "X_test = newsgroups_test.data\n",
    "y_test = newsgroups_test.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se define un pipeline de procesamiento con `TfidfVectorizer` y un modelo de Naive Bayes como clasificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english', max_features=1000)),\n",
    "    ('model', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se define el grid de hiperparámetros para ambos modelos y el TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = [\n",
    "    {\n",
    "        'tfidf__max_df': np.linspace(0.5, 0.95, 5), \n",
    "        'tfidf__min_df': [1, 2, 5], \n",
    "        'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)], \n",
    "        'tfidf__max_features': [5000, 10000], \n",
    "        'tfidf__sublinear_tf': [True, False], \n",
    "        'model': [MultinomialNB()],\n",
    "        'model__alpha': np.linspace(0.01, 1.0, 20), \n",
    "        'model__fit_prior': [True, False]\n",
    "    },\n",
    "    {\n",
    "        'tfidf__max_df': np.linspace(0.5, 0.95, 5),\n",
    "        'tfidf__min_df': [1, 2, 5],\n",
    "        'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "        'tfidf__max_features': [5000, 10000],\n",
    "        'tfidf__sublinear_tf': [True, False],\n",
    "        'model': [ComplementNB()],\n",
    "        'model__alpha': np.linspace(0.01, 1.0, 20),\n",
    "        'model__fit_prior': [True, False],\n",
    "        'model__norm': [True, False]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se define una búsqueda aleatoria con F1-score macro como métrica de evaluación para buscar maximiazarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search = RandomizedSearchCV(\n",
    "    pipeline, \n",
    "    param_distributions=param_dist, \n",
    "    n_iter=15,\n",
    "    cv=5, \n",
    "    scoring='f1_macro',\n",
    "    random_state=42, \n",
    "    n_jobs=2  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realiza la búsqueda de hiperparámetros y el entrenamiento del mejor modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chris/desafio_1_nlp/venv/lib/python3.10/site-packages/numpy/ma/core.py:2881: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores Hiperparámetros: {'tfidf__sublinear_tf': False, 'tfidf__ngram_range': (1, 3), 'tfidf__min_df': 2, 'tfidf__max_features': 10000, 'tfidf__max_df': np.float64(0.6125), 'model__fit_prior': False, 'model__alpha': np.float64(0.21842105263157896), 'model': MultinomialNB()}\n",
      "F1 Macro Score: 0.6664192443453767\n"
     ]
    }
   ],
   "source": [
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Utilize the best model found by the RandomizedSearchCV\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred, average='macro') \n",
    "\n",
    "print(f\"Mejores Hiperparámetros: {random_search.best_params_}\")\n",
    "print(f\"F1 Macro Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ha realizado una búsqueda de hiperparámetros para los modelos `MultinomialNB` y `ComplementNB`. Se ha encontrado que la mejor configuración es la siguiente para el modelo `MultinomialNB`:\n",
    "\n",
    "- **`tfidf__sublinear_tf`**: `False`\n",
    "- **`tfidf__ngram_range`**: `(1, 3)`\n",
    "- **`tfidf__min_df`**: `2`\n",
    "- **`tfidf__max_features`**: `10000`\n",
    "- **`tfidf__max_df`**: `0.6125`\n",
    "- **`model__fit_prior`**: `False`\n",
    "- **`model__alpha`**: `0.2184`\n",
    "\n",
    "Con esta configuración, se ha logrado un **F1 Macro Score** de `0.6664`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Vectorización de palabras\n",
    "\n",
    "Transponer la matriz documento-término. De esa manera se obtiene una matriz término-documento que puede ser interpretada como una colección de vectorización de palabras. Estudiar ahora similaridad entre palabras tomando 5 palabras y estudiando sus 5 más similares. La elección de palabras no debe ser al azar para evitar la aparición de términos poco interpretables, elegirlas \"manualmente\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos la matriz témino-documento utilizando el vectorizador TF-IDF con los parámetros obtenidos en el punto anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    stop_words='english', \n",
    "    max_features=10000, \n",
    "    sublinear_tf=False, \n",
    "    ngram_range=(1, 1), \n",
    "    min_df=2, \n",
    "    max_df=0.6125\n",
    ")\n",
    "\n",
    "# Fit the vectorizer on the training data\n",
    "X_train_tfidf = vectorizer.fit_transform(newsgroups_train.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se transpone la matriz para obtener la matriz término-documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the TF-IDF matrix: (11314, 10000)\n",
      "Number of terms: 10000\n"
     ]
    }
   ],
   "source": [
    "X_terms_docs = X_train_tfidf.T \n",
    "terms = vectorizer.get_feature_names_out() \n",
    "\n",
    "print(f\"Shape of the TF-IDF matrix: {X_train_tfidf.shape}\")\n",
    "print(f\"Number of terms: {len(terms)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se calcula la similitud entre palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_similar_words(term, matrix, terms, top_n=5):\n",
    "    \"\"\"\n",
    "    Get the top similar words to a given term based on a similarity matrix.\n",
    "\n",
    "    Parameters:\n",
    "    - term (str): The term to find similar words for.\n",
    "    - matrix (numpy.ndarray): The similarity matrix.\n",
    "    - terms (list): The list of terms corresponding to the rows/columns of the matrix.\n",
    "    - top_n (int): The number of top similar words to return. Default is 5.\n",
    "\n",
    "    Returns:\n",
    "    - similar_words (list): A list of tuples containing the similar words and their similarity scores.\n",
    "    \"\"\"\n",
    "    # Get the index of the term in the terms list\n",
    "    idx = terms.tolist().index(term) \n",
    "    \n",
    "    # Get the term vector\n",
    "    term_vector = matrix[idx].toarray() \n",
    "    \n",
    "    # Calculate the cosine similarity between the term vector and the matrix\n",
    "    similarities = cosine_similarity(term_vector, matrix) \n",
    "    \n",
    "    # Get the indices of the most similar words\n",
    "    similar_indices = np.argsort(similarities[0])[::-1][1:top_n+1] \n",
    "    \n",
    "    # Get the similar words and their similarity scores\n",
    "    similar_words = [(terms[i], similarities[0][i]) for i in similar_indices]\n",
    "    return similar_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se seleccionarán cinco palabras que se consideran relevantes para el análisis de los documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_words = ['government', 'computer', 'windows', 'cell', 'information'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de la palabra: **\"government\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtienen las palabras más similares a la palabra **\"government\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - libertarian: 0.2216\n",
      " - encryption: 0.2084\n",
      " - regulation: 0.1987\n",
      " - people: 0.1959\n",
      " - agencies: 0.1893\n"
     ]
    }
   ],
   "source": [
    "similar_words = get_top_similar_words(selected_words[0], X_terms_docs, terms, top_n=5)\n",
    "\n",
    "for similar_word, similarity in similar_words:\n",
    "    print(f\" - {similar_word}: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, podemos ver que las palabras si mantienen una relación conceptual con la palabra seleccionada. Todas las palabras más similares están relacionadas con el gobierno y la política. Algunas de las palabras más similares son \"libertarian\", \"regulation\", \"people\". La palabra \"encryption\" no parece tener una relación directa con la palabra seleccionada, pero puede ser que en los documentos donde aparece la palabra \"government\" también aparezca la palabra \"encryption\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de la palabra: **\"computer\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtienen las palabras más similares a la palabra **\"computer\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - wu: 0.1283\n",
      " - graphics: 0.1130\n",
      " - drive: 0.1062\n",
      " - reboot: 0.1047\n",
      " - hackers: 0.1032\n"
     ]
    }
   ],
   "source": [
    "similar_words = get_top_similar_words(selected_words[1], X_terms_docs, terms, top_n=5)\n",
    "\n",
    "for similar_word, similarity in similar_words:\n",
    "    print(f\" - {similar_word}: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, podemos ver que las palabras más similares están relacionadas con la computación y la tecnología. Algunas que resaltan son \"graphics\", \"drive\", \"reboot\". Es interesante que se incluya \"wu\" como una de las palabras más similares, ya que por si sola no tiene una interpretación clara, por lo que se puede inferir que se debe a que aparece en documentos similares a los que aparece \"computer\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de la palabra: **\"windows\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtienen las palabras más similares a la palabra **\"windows\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - dos: 0.3108\n",
      " - ms: 0.2273\n",
      " - microsoft: 0.2075\n",
      " - file: 0.1927\n",
      " - nt: 0.1919\n"
     ]
    }
   ],
   "source": [
    "similar_words = get_top_similar_words(selected_words[2], X_terms_docs, terms, top_n=5)\n",
    "\n",
    "for similar_word, similarity in similar_words:\n",
    "    print(f\" - {similar_word}: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En caso es interesante, pues la palabra \"windows\" es un término que puede tener varios significados. En este caso, las palabras más similares están relacionadas con el sistema operativo de Microsoft. Prácticamente no se hace mencion a la palabra \"windows\" como una ventana o vidrio. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de la palabra: **\"cell\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtienen las palabras más similares a la palabra **\"cell\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - cells: 0.1927\n",
      " - iu: 0.1910\n",
      " - church: 0.1829\n",
      " - attendance: 0.1748\n",
      " - batteries: 0.1741\n"
     ]
    }
   ],
   "source": [
    "similar_words = get_top_similar_words(selected_words[3], X_terms_docs, terms, top_n=5)\n",
    "\n",
    "for similar_word, similarity in similar_words:\n",
    "    print(f\" - {similar_word}: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este es otra palabra que puede tener varios significados. En este caso, dado que la palabra \"cell\" no se limita a un solo significado, las palabras más similares vienen de diferentes tópicos. Mi interpretación del topico al que pertencen las palabras más similares es: \n",
    "- \"iu\" (unidad de medida de vitaminas)\n",
    "- \"church\" (iglesia)\n",
    "- \"attendance\" (asistencia)\n",
    "- \"batteries\" (baterías)\n",
    "\n",
    "Este caso resalta la importancia del vecindario de las palabras en el análisis de similaridad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de la palabra: **\"information\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtienen las palabras más similares a la palabra **\"information\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - thanks: 0.1311\n",
      " - send: 0.1287\n",
      " - looking: 0.1222\n",
      " - interested: 0.1180\n",
      " - appreciated: 0.1159\n"
     ]
    }
   ],
   "source": [
    "similar_words = get_top_similar_words(selected_words[4], X_terms_docs, terms, top_n=5)\n",
    "\n",
    "for similar_word, similarity in similar_words:\n",
    "    print(f\" - {similar_word}: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso es interesante, pues la palabra \"information\" generalmente se asocia con datos o conocimientos que se comparten. En su mayoría, las palabras más similares están relacionadas con un contexto de comunicación. Mostrando la importancia del vecindario de palabras una vez más."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
